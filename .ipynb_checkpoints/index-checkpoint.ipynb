{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2921b8d1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/CienciaDeDatosEspacial/GeoDataFrame_Analytics/blob/main/GeoDFs_Analytics.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "# Mining your GeoDataFrame\n",
    "\n",
    "This final session covers two main topics:\n",
    "\n",
    "* The computation of spatial distances\n",
    "\n",
    "* The computation of spatial indicators from the spatial data\n",
    "\n",
    "Let me first check what I have in the map geopackage file from Brazil, already reprojected:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c03fb-08dc-42d2-999c-ef1315ddb32f",
   "metadata": {},
   "source": [
    "# II. MINING SPATIAL DATA\n",
    "\n",
    "\n",
    "Here, I will use data from Peru:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d25af",
   "metadata": {},
   "source": [
    "## Mining several variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51761cd",
   "metadata": {},
   "source": [
    "Let me select some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables = ['Educ_sec_comp2019_pct',\n",
    "                     'NBI2017_pct', \n",
    "                     'Viv_sin_serv_hig2017_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see distribution\n",
    "sea.boxplot(datadisMap[selected_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2998446",
   "metadata": {},
   "source": [
    "Let me check their monotony:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e81b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap[selected_variables].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea.pairplot(\n",
    "    datadisMap[selected_variables], kind=\"reg\", diag_kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dcf5c5",
   "metadata": {},
   "source": [
    "Here, we can reverse the values of *Educ_sec_comp2019_pct*. First let me standardize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(datadisMap[selected_variables])\n",
    "sea.displot(pd.melt(pd.DataFrame(normalized_data,columns=selected_variables)),\n",
    "            x=\"value\", hue=\"variable\",kind=\"kde\",\n",
    "            log_scale=(False,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df652d1c",
   "metadata": {},
   "source": [
    "Let me create new variables with the standardized values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de888e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new names\n",
    "selected_variables_new_std=[s+'_std' for s in selected_variables]\n",
    "\n",
    "# add colunms\n",
    "datadisMap[selected_variables_new_std]=normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdfd1b",
   "metadata": {},
   "source": [
    "Now, it is easy to reverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap['Educ_sec_NO_comp2019_pct_std']=-1*datadisMap.Educ_sec_comp2019_pct_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be16ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a result:\n",
    "selected_variables_new_std = ['Educ_sec_NO_comp2019_pct_std',\n",
    "                     'NBI2017_pct_std', \n",
    "                     'Viv_sin_serv_hig2017_pct_std']\n",
    "sea.pairplot(\n",
    "    datadisMap[selected_variables_new_std], kind=\"reg\", diag_kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007649d",
   "metadata": {},
   "source": [
    "### Conventional Clustering\n",
    "\n",
    "Here, I will use the three variables to create clusters of districts. Let me explore how many clusters could be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad295ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "\n",
    "Z = hc.linkage(datadisMap[selected_variables_new_std], 'ward')\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('cases')\n",
    "plt.ylabel('distance')\n",
    "hc.dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=1,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45a8ce",
   "metadata": {},
   "source": [
    "The dendogram recommends three groups. Let me request six.\n",
    "\n",
    "Let me use a common hierarchical technique following a agglomerative approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering as agnes\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(12345)# Set seed for reproducibility\n",
    "\n",
    "# Initialize the algorithm, requesting 6 clusters\n",
    "model = agnes(linkage=\"ward\", n_clusters=6).fit(datadisMap[selected_variables_new_std])\n",
    "\n",
    "# Assign labels to main data table\n",
    "datadisMap[\"hc_ag6\"] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fdcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see distribution of districts\n",
    "datadisMap[\"hc_ag6\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87068ef",
   "metadata": {},
   "source": [
    "We could try to find the pattern that created the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap.groupby(\"hc_ag6\")[selected_variables_new_std].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dd2e3",
   "metadata": {},
   "source": [
    "Let me show you the six groups of districts which have similar behavior in three variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa279c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including\n",
    "# a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6\", categorical=True, legend=True, linewidth=0, ax=ax\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386825e",
   "metadata": {},
   "source": [
    "### Regionalization: Spatial Clustering \n",
    "\n",
    "Spatial clustering or Regionalization will force the contiguity of the polygons to make a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify previous funtion call to specify cluster model with spatial constraint\n",
    "\n",
    "model_queen = agnes(linkage=\"ward\", \n",
    "                    n_clusters=6,\n",
    "                    connectivity=w_queen.sparse).fit(datadisMap[selected_variables_new_std])\n",
    "# Fit algorithm to the data\n",
    "datadisMap[\"hc_ag6_wQueen\"] = model_queen.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab01abf",
   "metadata": {},
   "source": [
    "We knew this would happen because we have islands. Then this results may not be satisfactory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8465df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6_wQueen\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0,\n",
    "    ax=ax,\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da7ec9",
   "metadata": {},
   "source": [
    "We have a couple the KNN alternative. Let's use that instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wknn8 = agnes(linkage=\"ward\",\n",
    "                    n_clusters=6,\n",
    "                    connectivity=w_knn8.sparse).fit(datadisMap[selected_variables_new_std])\n",
    "datadisMap[\"hc_ag6_wknn8\"] = model_wknn8.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0babe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(10, 12))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datadisMap.plot(\n",
    "    column=\"hc_ag6_wknn8\",\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0,\n",
    "    ax=ax,\n",
    ")\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bab781",
   "metadata": {},
   "source": [
    "We could evaluate two aspects of these clustering results:\n",
    "\n",
    "* “Compactness” of cluster shape, using the isoperimetric quotient (IPQ). This compares the area of the region to the area of a circle with the same perimeter as the region. For this measure, more compact shapes have an IPQ closer to 1, whereas very elongated or spindly shapes will have IPQs closer to zero. For the clustering solutions, we would expect the IPQ to be very small indeed, since the perimeter of a cluster/region gets smaller the more boundaries that members share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda import shape as shapestats\n",
    "results={}\n",
    "for cluster_type in (\"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the region polygons using a dissolve\n",
    "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
    "    # compute the actual isoperimetric quotient for these regions\n",
    "    ipqs = shapestats.isoperimetric_quotient(regions)\n",
    "    # cast to a dataframe\n",
    "    result = {cluster_type:ipqs}\n",
    "    results.update(result)\n",
    "# stack the series together along columns\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599c1e1",
   "metadata": {},
   "source": [
    "An alternative could be _convex_hull_ratio_, simply the division of the area of the cluster by the area of its convex hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17091459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda import shape as shapestats\n",
    "results={}\n",
    "for cluster_type in (\"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the region polygons using a dissolve\n",
    "    regions = datadisMap[[cluster_type, \"geometry\"]].to_crs(24892).dissolve(by=cluster_type)\n",
    "    # compute the actual convex hull quotient for these regions\n",
    "    chullr = shapestats.convex_hull_ratio(regions)\n",
    "    # cast to a dataframe\n",
    "    result = {cluster_type:chullr}\n",
    "    results.update(result)\n",
    "# stack the series together along columns\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d9146",
   "metadata": {},
   "source": [
    "In both cases, the spatial clusters do better.\n",
    "\n",
    "* Goodness of fit. Here we have two metrics:\n",
    "    - metrics.calinski_harabasz_score\n",
    "    - silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fit_scores = []\n",
    "for cluster_type in (\"hc_ag6_wknn8\", \"hc_ag6\"):\n",
    "    # compute the CH score\n",
    "    ch_score = metrics.calinski_harabasz_score(\n",
    "        # using scaled variables\n",
    "        datadisMap[selected_variables_new_std],\n",
    "        # using these labels\n",
    "        datadisMap[cluster_type],\n",
    "    )\n",
    "    sil_score = metrics.silhouette_score(\n",
    "        # using scaled variables\n",
    "        datadisMap[selected_variables_new_std],\n",
    "        # using these labels\n",
    "        datadisMap[cluster_type],\n",
    "    )\n",
    "    # and append the cluster type with the CH score\n",
    "    fit_scores.append((cluster_type, ch_score,sil_score))\n",
    "\n",
    "\n",
    "# re-arrange the scores into a dataframe for display\n",
    "pd.DataFrame(\n",
    "    fit_scores, columns=[\"cluster type\", \"CH score\", \"SIL score\"]\n",
    ").set_index(\"cluster type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d123df",
   "metadata": {},
   "source": [
    "Here, the conventional clustering beats the others, as you want bigger values in both.\n",
    "\n",
    "### Exercise 9\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "Use your three variables to carry out the cluster/regional analysis.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "### Conventional Regression\n",
    "\n",
    "This is a basic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.model import spreg\n",
    "\n",
    "dep_var_name=['NBI2017_pct']\n",
    "ind_vars_names=['Educ_sec_comp2019_pct','Viv_sin_serv_hig2017_pct']\n",
    "labels=['Lack Basic Needs %','High-School completed %', 'No H-Hold sanitation %']\n",
    "\n",
    "ols_model = spreg.OLS(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    # Dependent variable name\n",
    "    name_y=labels[0],\n",
    "    # Independent variable name\n",
    "    name_x=labels[1:],\n",
    "    name_ds='datadisMap')\n",
    "\n",
    "print(ols_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cedcec",
   "metadata": {},
   "source": [
    "Would we have some spatial effect playing we have not noticed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dependent variable\n",
    "moranNBI = Moran(datadisMap[dep_var_name], w_knn8)\n",
    "moranNBI.I,moranNBI.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the error term\n",
    "moranError = Moran(ols_model.u, w_knn8)\n",
    "moranError.I,moranError.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa787cb",
   "metadata": {},
   "source": [
    "We have a strong suggestion that either or both are playing here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40c6e8",
   "metadata": {},
   "source": [
    "### Spatial Regression\n",
    "\n",
    "I.  Spatial Lag Regression  (the dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAC_model = spreg.ML_Lag(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=labels[0],\n",
    "    # Independent variable name\n",
    "    name_x=labels[1:],\n",
    "    name_w='KNN8',\n",
    "    name_ds='datadisMap'\n",
    "    )\n",
    "\n",
    "print(SAC_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4a445",
   "metadata": {},
   "source": [
    "As you get this: Coefficient W_NBI2017_pct (ρ = 0.571, p = 0.000), you know that a 10% increase in deprivation in neighboring areas leads to a 5.71% increase in local deprivation. Then, Poverty is highly \"contagious\" across nearby regions. A policy suggestion: Anti-poverty programs must target entire clusters (not just individual areas) to break spillover cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4dcb9",
   "metadata": {},
   "source": [
    "* Spatial Error Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SER_model = spreg.ML_Error(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=labels[0],\n",
    "    # Independent variable name\n",
    "    name_x=labels[1:],\n",
    "    name_w='KNN8',\n",
    "    name_ds='datadisMap'\n",
    "    )\n",
    "\n",
    "print(SER_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c94b0",
   "metadata": {},
   "source": [
    "Strong Spatial Spillovers (λ = 0.837), meaning that 83.7% of unobserved deprivation factors (e.g., informal economies, cultural norms) spill over from neighboring areas. Then, poverty is highly contagious across space—a 10% deprivation increase in nearby regions raises local deprivation by 8.37% through hidden channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91e223",
   "metadata": {},
   "source": [
    "What if?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c230e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAC_model = spreg.GM_Combo_Het(\n",
    "    # Dependent variable\n",
    "    datadisMap[dep_var_name].values,\n",
    "    # Independent variables\n",
    "    datadisMap[ind_vars_names].values,\n",
    "    w=w_knn8,\n",
    "    # Dependent variable name\n",
    "    name_y=labels[0],\n",
    "    # Independent variable name\n",
    "    name_x=labels[1:],\n",
    "    name_w='KNN8',\n",
    "    name_ds='datadisMap'\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(SAC_model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7175b6",
   "metadata": {},
   "source": [
    "The SAR is not needed, neither the SAC; SER is what matters; in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857a017",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "Use your three variables to carry out regression analysis (conventional and spatial).\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
